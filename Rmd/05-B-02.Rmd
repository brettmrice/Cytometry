# Method Calibration {-}

## **Overview of Method Calibration** {-}

*   **Definition:** Method calibration is the process of establishing the relationship between the signal produced by an instrument and the known concentration or amount of an analyte
*   **Purpose:**
    *   Accurate Quantification: To ensure that the results of an assay are accurate and reliable
    *   Standardization: To standardize the assay and make it comparable across different instruments, laboratories, and time points
    *   Traceability: To establish traceability to international standards, ensuring the accuracy of the results
*   **Key Components of Method Calibration:**
    *   Standards
    *   Controls

## **Standards** {-}

*   **Definition:** Highly purified substances with a known concentration or value that are used to calibrate an analytical method
*   **Purpose:**
    *   Establish a Standard Curve: To create a relationship between instrument signal and the known values of the standards
    *   Quantify Analytes: To determine the concentration or amount of the target analyte in unknown samples
*   **Types of Standards:**
    *   Primary Standards: Highly purified substances that are directly traceable to international standards
    *   Secondary Standards: Standards that are prepared from primary standards and are used for routine calibration
    *   Internal Standards: Substances that are added to the sample to correct for variations in sample preparation or instrument response
*   **Characteristics of Ideal Standards:**
    *   High Purity: Should be free from impurities that could interfere with the assay
    *   Known Concentration: Concentration should be accurately known and traceable to international standards
    *   Stability: Should be stable under the storage and handling conditions used
    *   Matrix Compatibility: Should be compatible with the sample matrix
*   **Requirements for standards:**
    *   Store and handle according to the manufacturer's instructions
    *   Establish a curve that meets the test and lab specifications
    *   Ensure the stability of all standards

## **Controls** {-}

*   **Definition:** Substances with a known or expected value that are used to monitor the performance of an analytical method and to assess the accuracy and precision of the results
*   **Purpose:**
    *   Monitor Assay Performance: To ensure that the assay is working as expected
    *   Assess Accuracy and Precision: To assess the accuracy and precision of the results
    *   Detect Problems: To identify problems with the instrument, reagents, or assay protocol
*   **Types of Controls:**
    *   Positive Controls: Samples that are known to contain the target analyte or exhibit the desired activity
    *   Negative Controls: Samples that are known not to contain the target analyte or exhibit the desired activity
    *   Quality Control (QC) Materials: Commercially available or in-house prepared materials that are used to monitor the performance of the assay
*   **Characteristics of Ideal Controls:**
    *   Stability: Should be stable under the storage and handling conditions used
    *   Matrix Compatibility: Should be compatible with the sample matrix
    *   Appropriate Range: Should have values that are within the clinically relevant range
    *   Commutability: Should behave like patient samples in the assay
*   **Considerations:**
    *   Run Controls Regularly: Run controls at the beginning of each run, after maintenance, and whenever there is a change in reagents or personnel
    *   Follow Control Procedures: Follow established procedures for preparing and analyzing controls
    *   Document Control Results: Document the results of the control analyses and take corrective action when necessary

## **Relationship Between Standards and Controls** {-}

*   **Standards are used to calibrate the assay, while controls are used to monitor the performance of the calibrated assay**
*   Standards are used to establish the relationship between instrument signal and analyte concentration, while controls are used to verify that the relationship remains stable over time
*   Standards are used to ensure accuracy, while controls are used to ensure precision

## **Establishing a Standard Curve** {-}

*   **Definition:** A graph that plots the instrument signal against the known concentrations of the standards
*   **Purpose:**
    *   Quantify Analytes: To determine the concentration or amount of the target analyte in unknown samples
*   **Procedure:**
    1.  Prepare a series of standards with known concentrations of the analyte
    2.  Run the standards on the flow cytometer
    3.  Plot the instrument signal (e.g., mean fluorescence intensity) against the known concentrations
    4.  Fit a curve to the data points using a mathematical function (e.g., linear, logarithmic, exponential)
    5.  Assess the goodness of fit of the curve using statistical methods (e.g., R-squared, residual analysis)
*   **Considerations:**
    *   Number of Standards: Use an adequate number of standards to accurately define the curve (e.g., at least five standards)
    *   Concentration Range: Select a concentration range that spans the expected range of the analyte in the samples
    *   Curve-Fitting Method: Choose a curve-fitting method that is appropriate for the data
    *   Data Transformation: Consider transforming the data (e.g., using a logarithmic transformation) to improve the linearity of the relationship

## **Troubleshooting Calibration Issues** {-}

*   **Non-Linear Standard Curve:**
    *   *Possible Causes:*
        *   Incorrect standard concentrations
        *   Reagent degradation
        *   Instrument malfunction
    *   *Troubleshooting Steps:*
        *   Verify standard concentrations
        *   Replace suspect reagents
        *   Calibrate instrument
*   **Control Values Out of Range:**
    *   *Possible Causes:*
        *   Calibration errors
        *   Reagent degradation
        *   Incorrect sample preparation
    *   *Troubleshooting Steps:*
        *   Repeat calibration
        *   Replace suspect reagents
        *   Review sample preparation protocols